{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 358,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Wczytanie i preprocessing danych"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 359,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "count    4124.000000\n",
      "mean       11.055771\n",
      "std         7.717030\n",
      "min         0.000000\n",
      "25%         5.000000\n",
      "50%        11.000000\n",
      "75%        16.000000\n",
      "max        27.000000\n",
      "Name: N_elevators, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "house_data = pd.read_csv(\"train_data.csv\")\n",
    "\n",
    "print(house_data.N_elevators.describe())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>YearBuilt</th>\n",
       "      <th>Size(sqf)</th>\n",
       "      <th>Floor</th>\n",
       "      <th>HeatingType</th>\n",
       "      <th>AptManageType</th>\n",
       "      <th>N_Parkinglot(Ground)</th>\n",
       "      <th>N_Parkinglot(Basement)</th>\n",
       "      <th>N_manager</th>\n",
       "      <th>N_elevators</th>\n",
       "      <th>N_FacilitiesInApt</th>\n",
       "      <th>...</th>\n",
       "      <th>SubwayStation_Banwoldang</th>\n",
       "      <th>SubwayStation_Chil-sung-market</th>\n",
       "      <th>SubwayStation_Daegu</th>\n",
       "      <th>SubwayStation_Kyungbuk_uni_hospital</th>\n",
       "      <th>SubwayStation_Myung-duk</th>\n",
       "      <th>SubwayStation_Sin-nam</th>\n",
       "      <th>SubwayStation_no_subway_nearby</th>\n",
       "      <th>SalePrice_0</th>\n",
       "      <th>SalePrice_1</th>\n",
       "      <th>SalePrice_2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2006</td>\n",
       "      <td>814</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>111</td>\n",
       "      <td>184</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1985</td>\n",
       "      <td>587</td>\n",
       "      <td>8</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>80</td>\n",
       "      <td>76</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1985</td>\n",
       "      <td>587</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>80</td>\n",
       "      <td>76</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2006</td>\n",
       "      <td>2056</td>\n",
       "      <td>8</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>249</td>\n",
       "      <td>536</td>\n",
       "      <td>5</td>\n",
       "      <td>11</td>\n",
       "      <td>5</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1992</td>\n",
       "      <td>644</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>142</td>\n",
       "      <td>79</td>\n",
       "      <td>4</td>\n",
       "      <td>8</td>\n",
       "      <td>3</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 34 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   YearBuilt  Size(sqf)  Floor  HeatingType  AptManageType  \\\n",
       "0       2006        814      3            1              1   \n",
       "1       1985        587      8            1              0   \n",
       "2       1985        587      6            1              0   \n",
       "3       2006       2056      8            1              1   \n",
       "4       1992        644      2            1              0   \n",
       "\n",
       "   N_Parkinglot(Ground)  N_Parkinglot(Basement)  N_manager  N_elevators  \\\n",
       "0                   111                     184          3            0   \n",
       "1                    80                      76          2            2   \n",
       "2                    80                      76          2            2   \n",
       "3                   249                     536          5           11   \n",
       "4                   142                      79          4            8   \n",
       "\n",
       "   N_FacilitiesInApt  ...  SubwayStation_Banwoldang  \\\n",
       "0                  5  ...                         0   \n",
       "1                  3  ...                         0   \n",
       "2                  3  ...                         0   \n",
       "3                  5  ...                         0   \n",
       "4                  3  ...                         0   \n",
       "\n",
       "   SubwayStation_Chil-sung-market  SubwayStation_Daegu  \\\n",
       "0                               0                    0   \n",
       "1                               0                    1   \n",
       "2                               0                    1   \n",
       "3                               0                    0   \n",
       "4                               0                    0   \n",
       "\n",
       "   SubwayStation_Kyungbuk_uni_hospital  SubwayStation_Myung-duk  \\\n",
       "0                                    1                        0   \n",
       "1                                    0                        0   \n",
       "2                                    0                        0   \n",
       "3                                    0                        0   \n",
       "4                                    0                        1   \n",
       "\n",
       "   SubwayStation_Sin-nam  SubwayStation_no_subway_nearby  SalePrice_0  \\\n",
       "0                      0                               0            0   \n",
       "1                      0                               0            1   \n",
       "2                      0                               0            1   \n",
       "3                      1                               0            0   \n",
       "4                      0                               0            1   \n",
       "\n",
       "   SalePrice_1  SalePrice_2  \n",
       "0            1            0  \n",
       "1            0            0  \n",
       "2            0            0  \n",
       "3            0            1  \n",
       "4            0            0  \n",
       "\n",
       "[5 rows x 34 columns]"
      ]
     },
     "execution_count": 360,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "house_data = house_data.drop(columns=[])\n",
    "house_data.HeatingType = (house_data.HeatingType == \"individual_heating\").astype(int)\n",
    "house_data.AptManageType = (house_data.AptManageType == \"management_in_trust\").astype(int)\n",
    "\n",
    "categorical_columns = house_data.select_dtypes(include=['object']).columns\n",
    "house_data = pd.get_dummies(house_data, columns=categorical_columns)\n",
    "\n",
    "# We have 3 classes - 1. SalePrice < 100000, 2. 1000000 <= SalePrice < 350000, 3. SalePrice >= 350000\n",
    "house_data['SalePrice'] = pd.cut(house_data['SalePrice'], bins=[0, 100000, 350000, 1000000], labels=[0, 1, 2])\n",
    "house_data = pd.get_dummies(house_data, columns=['SalePrice'])\n",
    "\n",
    "# -> int\n",
    "house_data = house_data.astype(int)\n",
    "\n",
    "house_data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Niezbalansowanie danych"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 361,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "562\n",
      "2992\n",
      "570\n"
     ]
    }
   ],
   "source": [
    "# Print number of classes\n",
    "print(house_data['SalePrice_0'].sum())\n",
    "print(house_data['SalePrice_1'].sum())\n",
    "print(house_data['SalePrice_2'].sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Przygotowanie zbiorÃ³w"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 362,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "YearBuilt                              int64\n",
      "Size(sqf)                              int64\n",
      "Floor                                  int64\n",
      "HeatingType                            int64\n",
      "AptManageType                          int64\n",
      "N_Parkinglot(Ground)                   int64\n",
      "N_Parkinglot(Basement)                 int64\n",
      "N_manager                              int64\n",
      "N_elevators                            int64\n",
      "N_FacilitiesInApt                      int64\n",
      "N_FacilitiesNearBy(Total)              int64\n",
      "N_SchoolNearBy(Total)                  int64\n",
      "HallwayType_corridor                   int64\n",
      "HallwayType_mixed                      int64\n",
      "HallwayType_terraced                   int64\n",
      "TimeToBusStop_0~5min                   int64\n",
      "TimeToBusStop_10min~15min              int64\n",
      "TimeToBusStop_5min~10min               int64\n",
      "TimeToSubway_0-5min                    int64\n",
      "TimeToSubway_10min~15min               int64\n",
      "TimeToSubway_15min~20min               int64\n",
      "TimeToSubway_5min~10min                int64\n",
      "TimeToSubway_no_bus_stop_nearby        int64\n",
      "SubwayStation_Bangoge                  int64\n",
      "SubwayStation_Banwoldang               int64\n",
      "SubwayStation_Chil-sung-market         int64\n",
      "SubwayStation_Daegu                    int64\n",
      "SubwayStation_Kyungbuk_uni_hospital    int64\n",
      "SubwayStation_Myung-duk                int64\n",
      "SubwayStation_Sin-nam                  int64\n",
      "SubwayStation_no_subway_nearby         int64\n",
      "SalePrice_0                            int64\n",
      "SalePrice_1                            int64\n",
      "SalePrice_2                            int64\n",
      "dtype: object\n"
     ]
    }
   ],
   "source": [
    "train = house_data.sample(frac=0.8, random_state=200)  # random state is a seed value\n",
    "test = house_data.drop(train.index)\n",
    "\n",
    "# Shape\n",
    "print(train.dtypes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_y = train[['SalePrice_0', 'SalePrice_1', 'SalePrice_2']]\n",
    "train_x = train.drop(columns=['SalePrice_0', 'SalePrice_1', 'SalePrice_2'])\n",
    "test_y = test[['SalePrice_0', 'SalePrice_1', 'SalePrice_2']]\n",
    "test_x = test.drop(columns=['SalePrice_0', 'SalePrice_1', 'SalePrice_2'])\n",
    "\n",
    "# Normalize data\n",
    "train_x = (train_x - train_x.mean()) / train_x.std()\n",
    "test_x = (test_x - test_x.mean()) / test_x.std()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 364,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([ 1.2634, -0.1147,  0.4035,  0.2167,  0.2580, -0.4882,  1.4904,  0.2257,\n",
       "          1.1610,  1.3865,  1.1980,  1.3756, -0.3510, -0.6462,  0.8238,  0.5536,\n",
       "         -0.0958, -0.5395,  1.0589, -0.3819, -0.4482, -0.4924, -0.2009, -0.3819,\n",
       "         -0.3876, -0.1395, -0.1202, -0.6091,  1.6798, -0.3521, -0.2660],\n",
       "        dtype=torch.float64),\n",
       " tensor([0, 0, 1]))"
      ]
     },
     "execution_count": 364,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "import torch.utils.data as data\n",
    "import torch.nn as nn\n",
    "\n",
    "train_dataset = data.TensorDataset(\n",
    "    torch.from_numpy(train_x.values), torch.from_numpy(train_y.values)\n",
    ")\n",
    "test_dataset = data.TensorDataset(\n",
    "    torch.from_numpy(test_x.values), torch.from_numpy(test_y.values)\n",
    ")\n",
    "\n",
    "next(iter(train_dataset))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SieÄ‡ neuronowa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 365,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "# GPU operations have a separate seed we also want to set\n",
    "if torch.cuda.is_available():\n",
    "    torch.cuda.manual_seed(42)\n",
    "    torch.cuda.manual_seed_all(42)\n",
    "\n",
    "# Additionally, some operations on a GPU are implemented stochastic for efficiency\n",
    "# We want to ensure that all operations are deterministic on GPU (if used) for reproducibility\n",
    "torch.backends.cudnn.deterministic = True\n",
    "torch.backends.cudnn.benchmark = False\n",
    "\n",
    "\n",
    "class HouseNet(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(HouseNet, self).__init__()\n",
    "        self.lin1 =nn.Linear(31, 48)\n",
    "        self.bn1 = nn.BatchNorm1d(48)\n",
    "        self.act1 =nn.ReLU()\n",
    "        self.lin2 =nn.Linear(48, 48)\n",
    "        self.bn2 = nn.BatchNorm1d(48)\n",
    "        self.act2 =nn.ReLU()\n",
    "        self.lin3 =nn.Linear(48, 3)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.lin1(x)\n",
    "        x = self.bn1(x)\n",
    "        x = self.act1(x)\n",
    "        x = self.lin2(x)\n",
    "        x = self.bn2(x)\n",
    "        x = self.act2(x)\n",
    "        x = self.lin3(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 366,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "HouseNet(\n",
       "  (lin1): Linear(in_features=31, out_features=48, bias=True)\n",
       "  (bn1): BatchNorm1d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (act1): ReLU()\n",
       "  (lin2): Linear(in_features=48, out_features=48, bias=True)\n",
       "  (bn2): BatchNorm1d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (act2): ReLU()\n",
       "  (lin3): Linear(in_features=48, out_features=3, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 366,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Prepare model\n",
    "device = torch.device(\"cpu\")\n",
    "model = HouseNet()\n",
    "model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 367,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
    "loss_module = nn.MSELoss()\n",
    "\n",
    "train_data_loader = data.DataLoader(train_dataset, batch_size=128, shuffle=True)\n",
    "test_data_loader = data.DataLoader(\n",
    "    test_dataset, batch_size=len(test_dataset), shuffle=True, drop_last=False\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Trenowanie modelu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 368,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1, loss: 0.115\n",
      "Epoch: 2, loss: 0.0766\n",
      "Epoch: 3, loss: 0.0919\n",
      "Epoch: 4, loss: 0.0795\n",
      "Epoch: 5, loss: 0.0875\n",
      "Epoch: 6, loss: 0.0697\n",
      "Epoch: 7, loss: 0.0798\n",
      "Epoch: 8, loss: 0.0472\n",
      "Epoch: 9, loss: 0.0848\n",
      "Epoch: 10, loss: 0.0712\n",
      "Epoch: 11, loss: 0.0779\n",
      "Epoch: 12, loss: 0.094\n",
      "Epoch: 13, loss: 0.0623\n",
      "Epoch: 14, loss: 0.0934\n",
      "Epoch: 15, loss: 0.0794\n",
      "Epoch: 16, loss: 0.0655\n",
      "Epoch: 17, loss: 0.0655\n",
      "Epoch: 18, loss: 0.0903\n",
      "Epoch: 19, loss: 0.0544\n",
      "Epoch: 20, loss: 0.0655\n",
      "Epoch: 21, loss: 0.0683\n",
      "Epoch: 22, loss: 0.07\n",
      "Epoch: 23, loss: 0.0692\n",
      "Epoch: 24, loss: 0.0798\n",
      "Epoch: 25, loss: 0.0673\n",
      "Epoch: 26, loss: 0.0567\n",
      "Epoch: 27, loss: 0.0494\n",
      "Epoch: 28, loss: 0.0531\n",
      "Epoch: 29, loss: 0.0638\n",
      "Epoch: 30, loss: 0.0808\n",
      "Epoch: 31, loss: 0.0826\n",
      "Epoch: 32, loss: 0.0653\n",
      "Epoch: 33, loss: 0.0653\n",
      "Epoch: 34, loss: 0.0762\n",
      "Epoch: 35, loss: 0.0659\n",
      "Epoch: 36, loss: 0.0655\n",
      "Epoch: 37, loss: 0.0678\n",
      "Epoch: 38, loss: 0.0576\n",
      "Epoch: 39, loss: 0.063\n",
      "Epoch: 40, loss: 0.053\n",
      "Epoch: 41, loss: 0.0595\n",
      "Epoch: 42, loss: 0.0611\n",
      "Epoch: 43, loss: 0.0596\n",
      "Epoch: 44, loss: 0.0745\n",
      "Epoch: 45, loss: 0.0765\n",
      "Epoch: 46, loss: 0.0643\n",
      "Epoch: 47, loss: 0.0653\n",
      "Epoch: 48, loss: 0.0388\n",
      "Epoch: 49, loss: 0.0673\n",
      "Epoch: 50, loss: 0.0499\n",
      "Epoch: 51, loss: 0.0562\n",
      "Epoch: 52, loss: 0.0629\n",
      "Epoch: 53, loss: 0.0567\n",
      "Epoch: 54, loss: 0.0651\n",
      "Epoch: 55, loss: 0.0476\n",
      "Epoch: 56, loss: 0.0645\n",
      "Epoch: 57, loss: 0.0654\n",
      "Epoch: 58, loss: 0.0601\n",
      "Epoch: 59, loss: 0.0733\n",
      "Epoch: 60, loss: 0.0882\n",
      "Epoch: 61, loss: 0.064\n",
      "Epoch: 62, loss: 0.0722\n",
      "Epoch: 63, loss: 0.0485\n",
      "Epoch: 64, loss: 0.0439\n",
      "Epoch: 65, loss: 0.0633\n",
      "Epoch: 66, loss: 0.0444\n",
      "Epoch: 67, loss: 0.0692\n",
      "Epoch: 68, loss: 0.0743\n",
      "Epoch: 69, loss: 0.0415\n",
      "Epoch: 70, loss: 0.0518\n",
      "Epoch: 71, loss: 0.0664\n",
      "Epoch: 72, loss: 0.0603\n",
      "Epoch: 73, loss: 0.058\n",
      "Epoch: 74, loss: 0.0503\n",
      "Epoch: 75, loss: 0.0625\n",
      "Epoch: 76, loss: 0.0534\n",
      "Epoch: 77, loss: 0.0484\n",
      "Epoch: 78, loss: 0.0665\n",
      "Epoch: 79, loss: 0.069\n",
      "Epoch: 80, loss: 0.0698\n",
      "Epoch: 81, loss: 0.0565\n",
      "Epoch: 82, loss: 0.0705\n",
      "Epoch: 83, loss: 0.0464\n",
      "Epoch: 84, loss: 0.0451\n",
      "Epoch: 85, loss: 0.063\n",
      "Epoch: 86, loss: 0.055\n",
      "Epoch: 87, loss: 0.0595\n",
      "Epoch: 88, loss: 0.0687\n",
      "Epoch: 89, loss: 0.0638\n",
      "Epoch: 90, loss: 0.0797\n",
      "Epoch: 91, loss: 0.0718\n",
      "Epoch: 92, loss: 0.0485\n",
      "Epoch: 93, loss: 0.0597\n",
      "Epoch: 94, loss: 0.0767\n",
      "Epoch: 95, loss: 0.0655\n",
      "Epoch: 96, loss: 0.0622\n",
      "Epoch: 97, loss: 0.0457\n",
      "Epoch: 98, loss: 0.0581\n",
      "Epoch: 99, loss: 0.0617\n",
      "Epoch: 100, loss: 0.0541\n",
      "Epoch: 101, loss: 0.0637\n",
      "Epoch: 102, loss: 0.0477\n",
      "Epoch: 103, loss: 0.0558\n",
      "Epoch: 104, loss: 0.0622\n",
      "Epoch: 105, loss: 0.049\n",
      "Epoch: 106, loss: 0.0551\n",
      "Epoch: 107, loss: 0.0612\n",
      "Epoch: 108, loss: 0.0501\n",
      "Epoch: 109, loss: 0.0726\n",
      "Epoch: 110, loss: 0.101\n",
      "Epoch: 111, loss: 0.0551\n",
      "Epoch: 112, loss: 0.0605\n",
      "Epoch: 113, loss: 0.073\n",
      "Epoch: 114, loss: 0.0591\n",
      "Epoch: 115, loss: 0.0585\n",
      "Epoch: 116, loss: 0.0677\n",
      "Epoch: 117, loss: 0.0459\n",
      "Epoch: 118, loss: 0.0581\n",
      "Epoch: 119, loss: 0.0497\n",
      "Epoch: 120, loss: 0.0572\n",
      "Epoch: 121, loss: 0.0636\n",
      "Epoch: 122, loss: 0.0518\n",
      "Epoch: 123, loss: 0.0708\n",
      "Epoch: 124, loss: 0.0595\n",
      "Epoch: 125, loss: 0.0657\n",
      "Epoch: 126, loss: 0.0626\n",
      "Epoch: 127, loss: 0.0532\n",
      "Epoch: 128, loss: 0.0693\n",
      "Epoch: 129, loss: 0.0557\n",
      "Epoch: 130, loss: 0.0662\n",
      "Epoch: 131, loss: 0.0497\n",
      "Epoch: 132, loss: 0.0623\n",
      "Epoch: 133, loss: 0.0656\n",
      "Epoch: 134, loss: 0.0481\n",
      "Epoch: 135, loss: 0.0577\n",
      "Epoch: 136, loss: 0.0554\n",
      "Epoch: 137, loss: 0.0594\n",
      "Epoch: 138, loss: 0.0586\n",
      "Epoch: 139, loss: 0.0499\n",
      "Epoch: 140, loss: 0.0739\n",
      "Epoch: 141, loss: 0.0605\n",
      "Epoch: 142, loss: 0.0552\n",
      "Epoch: 143, loss: 0.0576\n",
      "Epoch: 144, loss: 0.0372\n",
      "Epoch: 145, loss: 0.0754\n",
      "Epoch: 146, loss: 0.0538\n",
      "Epoch: 147, loss: 0.0478\n",
      "Epoch: 148, loss: 0.0621\n",
      "Epoch: 149, loss: 0.0522\n",
      "Epoch: 150, loss: 0.0504\n",
      "Epoch: 151, loss: 0.0606\n",
      "Epoch: 152, loss: 0.0673\n",
      "Epoch: 153, loss: 0.056\n",
      "Epoch: 154, loss: 0.0547\n",
      "Epoch: 155, loss: 0.0715\n",
      "Epoch: 156, loss: 0.0762\n",
      "Epoch: 157, loss: 0.0576\n",
      "Epoch: 158, loss: 0.0707\n",
      "Epoch: 159, loss: 0.076\n",
      "Epoch: 160, loss: 0.098\n",
      "Epoch: 161, loss: 0.0785\n",
      "Epoch: 162, loss: 0.0782\n",
      "Epoch: 163, loss: 0.0657\n",
      "Epoch: 164, loss: 0.0559\n",
      "Epoch: 165, loss: 0.0785\n",
      "Epoch: 166, loss: 0.0681\n",
      "Epoch: 167, loss: 0.0411\n",
      "Epoch: 168, loss: 0.0457\n",
      "Epoch: 169, loss: 0.0561\n",
      "Epoch: 170, loss: 0.0629\n",
      "Epoch: 171, loss: 0.0785\n",
      "Epoch: 172, loss: 0.0593\n",
      "Epoch: 173, loss: 0.0614\n",
      "Epoch: 174, loss: 0.0498\n",
      "Epoch: 175, loss: 0.0583\n",
      "Epoch: 176, loss: 0.0529\n",
      "Epoch: 177, loss: 0.0662\n",
      "Epoch: 178, loss: 0.0701\n",
      "Epoch: 179, loss: 0.0442\n",
      "Epoch: 180, loss: 0.0705\n",
      "Epoch: 181, loss: 0.0416\n",
      "Epoch: 182, loss: 0.0724\n",
      "Epoch: 183, loss: 0.0604\n",
      "Epoch: 184, loss: 0.0629\n",
      "Epoch: 185, loss: 0.0755\n",
      "Epoch: 186, loss: 0.0585\n",
      "Epoch: 187, loss: 0.0648\n",
      "Epoch: 188, loss: 0.0614\n",
      "Epoch: 189, loss: 0.0634\n",
      "Epoch: 190, loss: 0.0559\n",
      "Epoch: 191, loss: 0.0454\n",
      "Epoch: 192, loss: 0.0728\n",
      "Epoch: 193, loss: 0.0635\n",
      "Epoch: 194, loss: 0.0521\n",
      "Epoch: 195, loss: 0.0675\n",
      "Epoch: 196, loss: 0.0566\n",
      "Epoch: 197, loss: 0.0533\n",
      "Epoch: 198, loss: 0.056\n",
      "Epoch: 199, loss: 0.0624\n",
      "Epoch: 200, loss: 0.0378\n"
     ]
    }
   ],
   "source": [
    "# Train model\n",
    "model.train()\n",
    "\n",
    "# Training loop\n",
    "for epoch in range(200):\n",
    "    for data_inputs, data_labels in train_data_loader:\n",
    "        ## Step 1: Move input data to device (only strictly necessary if we use GPU)\n",
    "        data_inputs = data_inputs.to(device)\n",
    "        data_labels = data_labels.to(device)\n",
    "\n",
    "        ## Step 2: Run the model on the input data\n",
    "        preds = model(data_inputs.float())\n",
    "        preds = preds.squeeze(\n",
    "            dim=1\n",
    "        )  # Output is [Batch size, 1], but we want [Batch size]\n",
    "\n",
    "        ## Step 3: Calculate the loss\n",
    "        loss = loss_module(preds, data_labels.float())\n",
    "\n",
    "        ## Step 4: Perform backpropagation\n",
    "        # Before calculating the gradients, we need to ensure that they are all zero.\n",
    "        # The gradients would not be overwritten, but actually added to the existing ones.\n",
    "        optimizer.zero_grad()\n",
    "        # Perform backpropagation\n",
    "        loss.backward()\n",
    "\n",
    "        ## Step 5: Update the parameters\n",
    "        optimizer.step()\n",
    "    print(f\"Epoch: {epoch+1}, loss: {loss.item():.3}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testowanie modelu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.8703030303030304\n"
     ]
    }
   ],
   "source": [
    "model.eval()\n",
    "\n",
    "for data_inputs, data_labels in test_data_loader:\n",
    "    data_inputs = data_inputs.to(device)\n",
    "    data_labels = data_labels.to(device)\n",
    "\n",
    "    preds = model(data_inputs.float())\n",
    "    preds = preds.squeeze(dim=1)\n",
    "\n",
    "    # round to int\n",
    "    preds = torch.round(preds)\n",
    "\n",
    "    predicted = 0\n",
    "    for i in range(len(data_labels)):\n",
    "        if data_labels[i][0] == preds[i][0] and data_labels[i][1] == preds[i][1] and data_labels[i][2] == preds[i][2]:\n",
    "            predicted += 1\n",
    "    \n",
    "    print(f\"Accuracy: {predicted/len(data_labels)}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
